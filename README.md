# Spark-Azure-Databricks-E-commerce-Data-Pipeline-using
# ğŸ›’ *Build E-commerce Data Pipeline using Spark & Databricks*

## ğŸ“– **Project Overview**

ShopVista, a fast-growing e-commerce platform, struggled with fragmented datasets â€” orders, shipments, returns, and dimension data â€” spread across multiple sources. This led to **manual reporting**, **inconsistent insights**, and **delayed decision-making**.

The project builds a **Unified E-Commerce Data Lakehouse** using **Azure Databricks**, **ADLS Gen2**, and **Unity Catalog**, adopting the **Bronze â†’ Silver â†’ Gold** data architecture.

---

## ğŸ¯ **Objectives**

- Automate ingestion of e-commerce data (orders, returns, shipments, dimensions)  
- Standardize and clean data for consistency across all layers  
- Build an analytics-ready data model integrated with **Power BI**  
- Enable scalable and auditable governance with **Unity Catalog**  

---

## ğŸ§° **Tools & Technologies**

| **Layer**       | **Tool / Service**                | **Purpose**                                      |
|-----------------|-----------------------------------|-------------------------------------------------|
| **Ingestion**   | Databricks Autoloader (Structured Streaming) | Incremental data loading from ADLS               |
| **Storage**     | Azure Data Lake Storage (ADLS Gen2) | Centralized data repository                      |
| **Processing**  | Azure Databricks (PySpark)    | ETL and transformation                           |
| **Governance**  | Unity Catalog                | Centralized access control and schema registry  |
| **Visualization** | Power BI                      | BI dashboards and reports                        |

---

## ğŸ§± **Data Architecture**
![img.png](project_architecture.png)

## ğŸ—‚ **Folder Structure** (ADLS Container: `ecomm-raw-data`)

The folder structure within the **ADLS container** is organized by entity (table).  
**Fact tables** contain a **`landing/`** subfolder for incoming data files.

```plaintext
ecomm-raw-data/
â”‚
â”œâ”€â”€ brands/                # Product brands data
â”œâ”€â”€ category/              # Product category data
â”œâ”€â”€ customers/             # Customer demographic data
â”œâ”€â”€ date/                  # Date dimension table
â”œâ”€â”€ products/              # Product details data
â”‚
â”œâ”€â”€ order_items/           # Sales transactions (item-level data)
â”‚   â””â”€â”€ landing/           # â† Daily data landing zone for new items
â”‚
â”œâ”€â”€ order_shipments/       # Shipping details for orders
â”‚   â””â”€â”€ landing/           # â† Monthly data landing zone for shipments
â”‚
â”œâ”€â”€ order_returns/         # Product return data
â”‚   â””â”€â”€ landing/           # â† Monthly data landing zone for returns
â”‚
â””â”€â”€ checkpoint/            # â† Used by Databricks Autoloader for streaming
```

---

### ğŸ“Œ **Data Frequency**

- **order_items** â†’ Daily data ingestion  
- **order_shipments** & **order_returns** â†’ Monthly data ingestion  

---

## âš™ï¸ **ETL Workflow Overview**

| **Layer**   | **Description**                                                                 |
|-------------|---------------------------------------------------------------------------------|
| **Bronze**  | Raw ingestion using **Autoloader** into Delta tables with minimal transformation. |
| **Silver**  | Cleansed and schema-validated data. Reads directly from **Bronze** tables using **Unity Catalog**. |
| **Gold**    | Aggregated analytical tables for **Power BI** consumption.                       |

---
## ğŸ“Š **Power BI Reporting Layer**

Power BI connects to the **Gold layer** tables via **Databricks SQL Warehouse** for visual insights.

![img.png](ecommerce_analytics_report.jpg)
---

## âœ… **Outcomes**

- â±ï¸ Automated daily & monthly ingestion using Autoloader 
- ğŸ§© Unified and governed schemas via Unity Catalog  
- âš™ï¸ Simplified data transformations (PySpark & Delta)  
- ğŸ“Š Real-time insights in Power BI 
- ğŸš€ Scalable architecture  

CopyrightÂ©ï¸ Codebasics Inc. All rights reserved.
